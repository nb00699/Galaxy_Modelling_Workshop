{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3bbe8fb-4bb4-4aeb-9c12-55fcf404bbf0",
   "metadata": {},
   "source": [
    "# Generating a Mock Sample of a Multidimensional Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10b82f-595c-4daf-83a0-95080d5301e1",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8f3cf0f-77d9-4919-8eed-9f1c21a45cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c63e6-06f2-486c-ab2c-65aa63a36ac5",
   "metadata": {},
   "source": [
    "## Define the Parameters\n",
    "- The number of samples\n",
    "- The number of dimensions\n",
    "- The number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2532981-53b4-4d71-a406-7a8aaf69e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dimensions = 9  # Number of dimensions\n",
    "num_components = 10  # Number of Gaussian components\n",
    "num_samples = 10000  # Number of samples\n",
    "min_separation = 2.9  # Minimum separation between component means\n",
    "error_std = 0.1  # Standard deviation of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8960f23-f17f-4683-8db2-2b328b71d8e5",
   "metadata": {},
   "source": [
    "## Generating the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f38230cc-0e59-4571-9fba-1fe7e0386b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def generate_mock_data_with_errors(\n",
    "    num_dimensions, num_components, num_samples, min_separation, error_std\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate mock data from a Gaussian Mixture Model with full covariance matrices and add mock errors.\n",
    "    Ensures minimum separation between component means.\n",
    "\n",
    "    Parameters:\n",
    "        num_dimensions (int): Number of dimensions.\n",
    "        num_components (int): Number of Gaussian components.\n",
    "        num_samples (int): Number of samples to generate.\n",
    "        min_separation (float): Minimum distance between component means.\n",
    "        error_std (float): Standard deviation of the errors.\n",
    "\n",
    "    Returns:\n",
    "        X (numpy.ndarray): The sampled data points with errors (num_samples x num_dimensions).\n",
    "        y (numpy.ndarray): The labels for the components (num_samples,).\n",
    "        errors (numpy.ndarray): The mock errors added to the data (num_samples x num_dimensions).\n",
    "    \"\"\"\n",
    "    # Step 1: Generate means with minimum separation\n",
    "    means = []\n",
    "    while len(means) < num_components:\n",
    "        candidate_mean = np.random.uniform(-3, 3, size=num_dimensions)  # Generate mean in the range [-3, 3]\n",
    "        if all(np.linalg.norm(candidate_mean - existing_mean) >= min_separation for existing_mean in means):\n",
    "            means.append(candidate_mean)\n",
    "    means = np.array(means)\n",
    "\n",
    "    # Step 2: Generate full covariance matrices for each Gaussian component\n",
    "    covariances = []\n",
    "    for _ in range(num_components):\n",
    "        A = np.random.rand(num_dimensions, num_dimensions)  # Random square matrix\n",
    "        #regularization = np.eye(num_dimensions) * 0.3  # Regularization for positive-definiteness\n",
    "        full_cov = np.dot(A, A.T)  # Make positive-definite\n",
    "        covariances.append(full_cov)\n",
    "\n",
    "    # Normalize covariances to ensure reasonable scales\n",
    "    covariances = [cov / np.linalg.norm(cov) for cov in covariances]\n",
    "\n",
    "    # Further regularize the covariances\n",
    "    regularization = 1.2\n",
    "    covariances = [cov + np.eye(cov.shape[0]) * regularization for cov in covariances]\n",
    "\n",
    "    # Step 3: Generate mixture weights for the components\n",
    "    weights = np.random.dirichlet(np.ones(num_components), size=1).flatten()\n",
    "\n",
    "    # Step 4: Initialize a GaussianMixture object\n",
    "    gmm = GaussianMixture(n_components=num_components, covariance_type='full', random_state=42)\n",
    "\n",
    "    # Step 5: Manually set the GMM parameters\n",
    "    gmm.means_ = means  # Assign the generated means\n",
    "    gmm.covariances_ = np.array(covariances)\n",
    "    gmm.precisions_cholesky_ = np.linalg.cholesky(np.linalg.inv(gmm.covariances_))\n",
    "    gmm.weights_ = weights\n",
    "\n",
    "    # Step 6: Generate synthetic data\n",
    "    X, y = gmm.sample(num_samples)\n",
    "\n",
    "    # Step 7: Generate mock errors\n",
    "    errors = np.random.normal(0, error_std, size=X.shape)\n",
    "\n",
    "    # Step 8: Add errors to the original data\n",
    "    X = X + errors\n",
    "\n",
    "    # Step 9: Return the generated data with errors, labels, and errors themselves\n",
    "    return X, y, errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe18a1f2-6379-4b10-ac14-64c2cb150b5d",
   "metadata": {},
   "source": [
    "## Generating a plot for a two-dimensional case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b1e0152-ca8d-44b9-97b6-44bf95acc0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X, y):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    unique_labels = np.unique(y)\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        component_data = X[y == label]\n",
    "        plt.scatter(\n",
    "            component_data[:, 0], \n",
    "            component_data[:, 1], \n",
    "            label=f'Component {label}', \n",
    "            s=10\n",
    "        )\n",
    "    \n",
    "    plt.title('Generated Data from Gaussian Mixture Model')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.legend(title='Components', loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7da36fb-3d39-4642-8abb-5f36c312f93a",
   "metadata": {},
   "source": [
    "## Running the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c37560c-f7d3-4f93-8532-313b2e4fd6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generated with 10000 samples in 9 dimensions, with 10 components.\n"
     ]
    }
   ],
   "source": [
    "# Generate data with errors\n",
    "X, y, errors = generate_mock_data_with_errors(num_dimensions, num_components, num_samples, min_separation, error_std)\n",
    "\n",
    "# Plot if 2D\n",
    "if num_dimensions == 2:\n",
    "    plot_data(X, y)\n",
    "else:\n",
    "    print(f\"Data generated with {num_samples} samples in {num_dimensions} dimensions, with {num_components} components.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d659a-d822-4ae7-a443-3fd40231f95e",
   "metadata": {},
   "source": [
    "## Save Sampled Data to a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "032a8dc1-d015-4a60-9e48-38d5928e1e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_with_errors_to_csv(X, y, errors, filename=\"sampled_data_with_errors.csv\"):\n",
    "    \"\"\"\n",
    "    Save sampled data, errors, and their labels to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): The sampled data points (num_samples x num_dimensions).\n",
    "        y (numpy.ndarray): The labels for the components (num_samples,).\n",
    "        errors (numpy.ndarray): The errors for the data points (num_samples x num_dimensions).\n",
    "        filename (str): The name of the CSV file to save the data to.\n",
    "    \"\"\"\n",
    "    # Create column names for the data dimensions and errors\n",
    "    num_dimensions = X.shape[1]\n",
    "    data_columns = [f\"Dimension_{i+1}\" for i in range(num_dimensions)]\n",
    "    error_columns = [f\"Error_Dimension_{i+1}\" for i in range(num_dimensions)]\n",
    "\n",
    "    # Add the component labels column\n",
    "    all_columns = data_columns + error_columns + [\"Component_Label\"]\n",
    "\n",
    "    # Combine the data, errors, and labels into a single DataFrame\n",
    "    data_with_errors_and_labels = np.hstack((X, errors, y.reshape(-1, 1)))  # Combine X, errors, and y\n",
    "    df = pd.DataFrame(data_with_errors_and_labels, columns=all_columns)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data with errors successfully saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e45b2508-4c3c-4a1a-bdbc-8f8077433df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with errors successfully saved to generated_data_with_errors.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "save_data_with_errors_to_csv(X, y, errors, filename=\"generated_data_with_errors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c9fff-ce03-4eca-9f8d-84ea13789d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
